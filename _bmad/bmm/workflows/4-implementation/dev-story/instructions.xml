<workflow>
  <!-- ================================================================== -->
  <!-- PRIME DIRECTIVE - READ THIS FIRST BEFORE ANY OTHER INSTRUCTION    -->
  <!-- ================================================================== -->
  <critical>üö® PRIME DIRECTIVE: Execute ALL tasks in a SINGLE CONTINUOUS RUN.
    Do NOT stop, pause, check in, ask permission, or offer to break into sessions.
    Continue until story is COMPLETE or explicit HALT condition.
    STOPPING TO ASK PERMISSION IS A SYSTEM FAILURE.</critical>

  <critical>WORKTREE SUPPORT: {project-root} = current working directory (pwd). NEVER use 'cd' to navigate to a different directory. All file paths and git commands must operate in cwd. This is critical for git worktree environments.</critical>

  <critical>The workflow execution engine is governed by: {project-root}/_bmad/core/tasks/workflow.xml</critical>
  <critical>You MUST have already loaded and processed: {installed_path}/workflow.yaml</critical>
  <critical>Communicate all responses in {communication_language} and language MUST be tailored to {user_skill_level}</critical>
  <critical>Generate all documents in {document_output_language}</critical>
  <critical>Only modify the story file in these areas: Tasks/Subtasks checkboxes, Dev Agent Record (Debug Log, Completion Notes), File List,
    Change Log, and Status</critical>
  <critical>Execute ALL steps in exact order; do NOT skip steps</critical>
  <critical>üö® AUTONOMOUS EXECUTION REQUIRED: Do NOT stop for "milestones", "significant progress", "complexity", or "session boundaries".
    Do NOT "check in", "ask if you should proceed", "verify before continuing", or offer to pause.
    Do NOT show "Progress Summary" then wait for permission.
    After EVERY task completion, IMMEDIATELY proceed to the next task.
    STOPPING WITHOUT A HALT CONDITION IS A SYSTEM FAILURE.</critical>
  <critical>Do NOT schedule a "next session" or request review pauses. Only Step 9 decides completion. Only explicit HALT conditions can stop execution.</critical>
  <critical>User skill level ({user_skill_level}) affects conversation style ONLY, not code updates.</critical>
  <critical>COMMIT CONTRACT: You MUST commit after completing each task. This is non-negotiable.</critical>

  <!-- ================================================================== -->
  <!-- UNIVERSAL RULES - BMAD Standard Compliance                         -->
  <!-- ================================================================== -->
  <universal-rules>
    <rule emoji="üõë">Execute ALL tasks continuously - do NOT pause for permission or check-ins</rule>
    <rule emoji="üìñ">Read complete step instructions before taking any action</rule>
    <rule emoji="üîÑ">Process steps sequentially - never skip or optimize the sequence</rule>
    <rule emoji="üîí">Honor commit contract after every task - no batching allowed</rule>
    <rule emoji="üéØ">Follow story Tasks/Subtasks exactly as written - no deviation</rule>
    <rule emoji="üìã">You are an IMPLEMENTER executing the story, not a facilitator asking for permission</rule>
  </universal-rules>

  <!-- ================================================================== -->
  <!-- NOTE: Git state verification and branch setup is handled by        -->
  <!-- dev-begin workflow. This workflow expects to be invoked with       -->
  <!-- story_path and story_id already resolved.                          -->
  <!-- ================================================================== -->

  <step n="1" goal="Load story file and validate inputs">
    <critical>This workflow expects story_path to be provided by dev-begin orchestrator</critical>

    <!-- ADW SDK Integration: Check for story_id in ADW state file first -->
    <check if="environment variable ADW_STATE_FILE is set and file exists">
      <action>Read $ADW_STATE_FILE JSON content</action>
      <action>Check if "story_id" field exists and is non-empty</action>

      <check if="story_id exists in state file">
        <critical>Running in ADW environment - using story_id from state file</critical>
        <action>Extract story_id from state JSON (expected format: "1.2" or "1-2")</action>
        <action>Parse epic_num (first number) and story_num (second number) from story_id</action>
        <action>Find matching story file in {story_dir} using pattern: {{epic_num}}-{{story_num}}-*.md</action>

        <check if="story file found">
          <action>Set {{story_path}} to the found file path</action>
          <action>Read COMPLETE story file</action>
          <action>Extract story_key from filename</action>
          <output>ü§ñ **ADW Mode: Story Loaded from State**
            Story ID: {{story_id}}
            Path: {{story_path}}
            Story Key: {{story_key}}
          </output>
        </check>

        <check if="story file NOT found for story_id">
          <output>‚ö†Ô∏è ADW Mode: Could not find story file for ID: {{story_id}}</output>
          <action>Fall through to normal discovery flow</action>
        </check>
      </check>
    </check>

    <!-- Normal flow: Check if story_path was provided -->
    <check if="{{story_path}} is provided and not empty">
      <action>Use {{story_path}} directly</action>
      <action>Read COMPLETE story file</action>
      <action>Extract story_key from filename (e.g., "3-2-implement-widget" from path)</action>
      <output>üìñ **Story Loaded**
        Path: {{story_path}}
        Story Key: {{story_key}}
      </output>
    </check>

    <check if="{{story_path}} is NOT provided or empty">
      <!-- Fallback: Try to detect from current branch or prompt user -->
      <action>Run: git branch --show-current</action>
      <action>Store result as {{current_branch}}</action>

      <check if="{{current_branch}} matches pattern 'story/*'">
        <action>Extract story-key from branch name (story/X-Y-slug ‚Üí X-Y-slug)</action>
        <action>Store as {{story_key}}</action>
        <action>Find matching story file in {story_dir} using pattern: {{story_key}}*.md</action>
        <check if="story file found">
          <action>Read COMPLETE story file</action>
          <output>üìñ **Story Loaded from Branch**
            Branch: {{current_branch}}
            Story Key: {{story_key}}
          </output>
        </check>
        <check if="story file NOT found">
          <output>‚ö†Ô∏è Could not find story file for: {{story_key}}</output>
          <ask>Please provide the full path to the story file:</ask>
          <action>Store user-provided path as {{story_path}}</action>
          <action>Read COMPLETE story file</action>
        </check>
      </check>

      <check if="{{current_branch}} does NOT match 'story/*'">
        <output>‚ö†Ô∏è **No Story Context**

          This workflow expects to be invoked by dev-begin with a story path.
          Current branch: {{current_branch}}

          Please either:
          1. Run dev-begin workflow first (recommended)
          2. Provide a story file path manually
        </output>
        <ask>Provide story file path or type 'abort':</ask>
        <check if="user provides path">
          <action>Store as {{story_path}}</action>
          <action>Read COMPLETE story file</action>
          <action>Extract story_key from filename</action>
        </check>
        <check if="user types 'abort'">
          <action>HALT: "No story provided. Run dev-begin workflow first."</action>
        </check>
      </check>
    </check>

    <anchor id="task_check" />

    <action>Parse sections: Story, Acceptance Criteria, Tasks/Subtasks, Dev Notes, Dev Agent Record, File List, Change Log, Status</action>
    <action>Identify first incomplete task (unchecked [ ]) in Tasks/Subtasks</action>

    <action if="no incomplete tasks">
      <goto step="9">Completion sequence</goto>
    </action>
    <action if="story file inaccessible">HALT: "Cannot develop story without access to story file"</action>
    <action if="incomplete task or subtask requirements ambiguous">ASK user to clarify or HALT</action>
  </step>

  <step n="1b" goal="Load relevant conditional documentation">
    <critical>Check for relevant feature docs BEFORE implementation - prevents reinventing wheels!</critical>

    <action>Check if {project-root}/docs/CONDITIONAL_DOCS.md exists</action>

    <check if="CONDITIONAL_DOCS.md exists">
      <action>Read and parse the conditional docs guide</action>
      <action>Extract story context keywords from:
        - Story key (e.g., "3-2-implement-auth-middleware" ‚Üí "auth", "middleware", "implement")
        - Story title and description from loaded story file
        - Task descriptions in the story
      </action>

      <action>For each entry in CONDITIONAL_DOCS.md Documentation Map:
        - Parse the conditions list for that doc
        - Check if any condition keywords match story context keywords
        - Collect paths of all matching docs
      </action>

      <check if="matching docs found">
        <action>Load content of each matching feature doc</action>
        <action>Store combined content as {{conditional_docs_content}}</action>
        <output>üìö **Relevant Feature Documentation Loaded:**
          {{#matched_docs}}
          - {{doc_path}} (matched: "{{matched_condition}}")
          {{/matched_docs}}

          This existing knowledge will inform implementation decisions.
        </output>
      </check>

      <check if="no matching docs">
        <action>Set {{conditional_docs_content}} = empty</action>
        <output>‚ÑπÔ∏è No matching conditional docs found for this story context.</output>
      </check>
    </check>

    <check if="CONDITIONAL_DOCS.md does NOT exist">
      <action>Set {{conditional_docs_content}} = empty</action>
      <note>No conditional docs guide configured - skipping feature doc lookup</note>
    </check>
  </step>

  <step n="2" goal="Load project context and establish commit contract">
    <critical>Load all available context to inform implementation</critical>
    <critical>MANDATORY: Agent must explicitly state the commit contract before proceeding</critical>

    <action>Load {project_context} for coding standards and project-wide patterns (if exists)</action>

    <!-- Include conditional docs if loaded in step 1b -->
    <check if="{{conditional_docs_content}} is not empty">
      <action>Include {{conditional_docs_content}} in available context for implementation decisions</action>
      <note>This provides existing patterns and knowledge that matched this story's context - USE IT!</note>
    </check>
    <action>Load comprehensive context from story file's Dev Notes section</action>
    <action>Extract developer guidance from Dev Notes: architecture requirements, previous learnings, technical specifications</action>
    <action>Use enhanced story context to inform implementation decisions and approaches</action>

    <!-- ================================================================== -->
    <!-- COMMIT CONTRACT - Agent MUST verbally acknowledge this commitment  -->
    <!-- ================================================================== -->
    <critical>COMMIT CONTRACT ACKNOWLEDGMENT REQUIRED - MUST BE VERBALIZED EXACTLY AS WRITTEN</critical>
    <critical>üö® FAILURE TO COMMIT AFTER EACH TASK IS A SYSTEM FAILURE - NO EXCEPTIONS</critical>
    <output>üìã **COMMIT CONTRACT - I SHALL HONOR THIS**

      Before proceeding with implementation, I solemnly acknowledge and commit to the following:

      **üîí I SHALL COMMIT AFTER EVERY SINGLE TASK COMPLETION.**

      This means:
      - After EACH task passes validation, I SHALL immediately run `git add -A` and `git commit`
      - I SHALL use conventional commit format: `&lt;type&gt;(story-{{story_key}}): &lt;description&gt;`
      - I SHALL NOT proceed to the next task until the commit is verified
      - I SHALL NOT batch multiple tasks into one commit
      - I SHALL NOT skip commits under any circumstances
      - After each commit, I SHALL explicitly state: "‚úÖ COMMIT CONTRACT HONORED - Task N committed"

      **This contract is NON-NEGOTIABLE. Batching tasks or skipping commits is a SYSTEM FAILURE.**

      I understand that after completing Task 1, I must commit before starting Task 2.
      I understand that after completing Task 2, I must commit before starting Task 3.
      And so on for every task in this story.
    </output>

    <!-- ================================================================== -->
    <!-- CONTINUOUS EXECUTION CONTRACT - Agent MUST verbally acknowledge  -->
    <!-- ================================================================== -->
    <critical>CONTINUOUS EXECUTION CONTRACT ACKNOWLEDGMENT REQUIRED</critical>
    <output>üöÄ **Continuous Execution Contract**

      I also acknowledge and commit to the following:

      **‚ö° I WILL NOT STOP until the story is COMPLETE or a HALT condition is triggered.**

      This means:
      - I will NOT pause to "check in" or ask permission to continue
      - I will NOT offer to stop after completing tasks
      - I will NOT suggest breaking the work into sessions
      - After each task, I will IMMEDIATELY proceed to the next task
      - Only explicit HALT conditions in the workflow can stop me

      This contract is non-negotiable and I am bound by it for this entire session.
    </output>

    <!-- Initialize commit tracking -->
    <action>Initialize {{tasks_committed}} = 0</action>
    <action>Initialize {{current_task_number}} = 0</action>

    <output>‚úÖ **Context Loaded**
      Story and project context available for implementation
      Commit contract acknowledged and active
      Continuous execution contract acknowledged and active
      Commit counter initialized: 0 tasks committed
    </output>
  </step>

  <step n="3" goal="Detect review continuation and extract review context">
    <critical>Determine if this is a fresh start or continuation after code review</critical>

    <action>Check if "Senior Developer Review (AI)" section exists in the story file</action>
    <action>Check if "Review Follow-ups (AI)" subsection exists under Tasks/Subtasks</action>

    <check if="Senior Developer Review section exists">
      <action>Set review_continuation = true</action>
      <action>Extract from "Senior Developer Review (AI)" section:
        - Review outcome (Approve/Changes Requested/Blocked)
        - Review date
        - Total action items with checkboxes (count checked vs unchecked)
        - Severity breakdown (High/Med/Low counts)
      </action>
      <action>Count unchecked [ ] review follow-up tasks in "Review Follow-ups (AI)" subsection</action>
      <action>Store list of unchecked review items as {{pending_review_items}}</action>

      <output>‚èØÔ∏è **Resuming Story After Code Review** ({{review_date}})

        **Review Outcome:** {{review_outcome}}
        **Action Items:** {{unchecked_review_count}} remaining to address
        **Priorities:** {{high_count}} High, {{med_count}} Medium, {{low_count}} Low

        **Strategy:** Will prioritize review follow-up tasks (marked [AI-Review]) before continuing with regular tasks.
      </output>
    </check>

    <check if="Senior Developer Review section does NOT exist">
      <action>Set review_continuation = false</action>
      <action>Set {{pending_review_items}} = empty</action>

      <output>üöÄ **Starting Fresh Implementation**

        Story: {{story_key}}
        Story Status: {{current_status}}
        First incomplete task: {{first_task_description}}
      </output>
    </check>
  </step>

  <step n="4" goal="Mark story in-progress and update Linear" tag="sprint-status">
    <!-- Linear Issue Status Update -->
    <action>Check if project has .linear configuration file at {project-root}/.linear</action>
    <action>Extract Linear issue ID from story file's "Linear Issue:" field</action>

    <check if=".linear config exists AND linear_issue_id is valid (not empty or 'not-configured')">
      <action>Get team workflow states: python ~/.claude/skills/linear/scripts/get_teams.py --detailed --json</action>
      <action>Find the state ID for "In Progress" status</action>
      <action>Update Linear issue: python ~/.claude/skills/linear/scripts/update_issue.py {{linear_issue_id}} --state-id {{in_progress_state_id}}</action>
      <output>üîó **Linear Issue Updated:** {{linear_issue_id}} ‚Üí In Progress</output>
    </check>

    <check if=".linear config does NOT exist OR linear_issue_id is invalid">
      <note>Skipping Linear update - no configuration or issue ID</note>
    </check>

    <!-- Sprint Status Update -->
    <check if="{{sprint_status}} file exists">
      <action>Load the FULL file: {{sprint_status}}</action>
      <action>Read all development_status entries to find {{story_key}}</action>
      <action>Get current status value for development_status[{{story_key}}]</action>

      <check if="current status == 'ready-for-dev' OR review_continuation == true">
        <action>Update the story in the sprint status report to = "in-progress"</action>
        <output>üöÄ Starting work on story {{story_key}}
          Status updated: ready-for-dev ‚Üí in-progress
        </output>
      </check>

      <check if="current status == 'in-progress'">
        <output>‚èØÔ∏è Resuming work on story {{story_key}}
          Story is already marked in-progress
        </output>
      </check>

      <check if="current status is neither ready-for-dev nor in-progress">
        <output>‚ö†Ô∏è Unexpected story status: {{current_status}}
          Expected ready-for-dev or in-progress. Continuing anyway...
        </output>
      </check>

      <action>Store {{current_sprint_status}} for later use</action>
    </check>

    <check if="{{sprint_status}} file does NOT exist">
      <output>‚ÑπÔ∏è No sprint status file exists - story progress will be tracked in story file only</output>
      <action>Set {{current_sprint_status}} = "no-sprint-tracking"</action>
    </check>
  </step>

  <step n="5" goal="Implement task following red-green-refactor cycle">
    <critical>FOLLOW THE STORY FILE TASKS/SUBTASKS SEQUENCE EXACTLY AS WRITTEN - NO DEVIATION</critical>

    <!-- Track current task number -->
    <action>Increment {{current_task_number}} by 1</action>
    <output>üìå **Starting Task {{current_task_number}}** (Commits so far: {{tasks_committed}})</output>

    <action>Review the current task/subtask from the story file - this is your authoritative implementation guide</action>
    <action>Plan implementation following red-green-refactor cycle</action>

    <!-- RED PHASE -->
    <action>Write FAILING tests first for the task/subtask functionality</action>
    <action>Confirm tests fail before implementation - this validates test correctness</action>

    <!-- GREEN PHASE -->
    <action>Implement MINIMAL code to make tests pass</action>
    <action>Run tests to confirm they now pass</action>
    <action>Handle error conditions and edge cases as specified in task/subtask</action>

    <!-- REFACTOR PHASE -->
    <action>Improve code structure while keeping tests green</action>
    <action>Ensure code follows architecture patterns and coding standards from Dev Notes</action>

    <action>Document technical approach and decisions in Dev Agent Record ‚Üí Implementation Plan</action>

    <action if="new dependencies required beyond story specifications">HALT: "Additional dependencies need user approval"</action>
    <action if="3 consecutive implementation failures occur">HALT and request guidance</action>
    <action if="required configuration is missing">HALT: "Cannot proceed without necessary configuration files"</action>

    <critical>NEVER implement anything not mapped to a specific task/subtask in the story file</critical>
    <critical>NEVER proceed to next task until current task/subtask is complete AND tests pass</critical>
    <critical>üö® CONTINUOUS EXECUTION CONTRACT: Execute continuously without pausing. After each task, IMMEDIATELY start the next.
      Do NOT summarize progress and wait. Do NOT ask "should I continue?". Do NOT offer to pause.
      VIOLATION OF THIS CONTRACT IS A SYSTEM FAILURE.</critical>
  </step>

  <step n="6" goal="Author comprehensive tests">
    <action>Create unit tests for business logic and core functionality introduced/changed by the task</action>
    <action>Add integration tests for component interactions specified in story requirements</action>
    <action>Include end-to-end tests for critical user flows when story requirements demand them</action>
    <action>Cover edge cases and error handling scenarios identified in story Dev Notes</action>
  </step>

  <step n="7" goal="Run validations and tests">
    <action>Determine how to run tests for this repo (infer test framework from project structure)</action>
    <action>Run all existing tests to ensure no regressions</action>
    <action>Run the new tests to verify implementation correctness</action>
    <action>Run linting and code quality checks if configured in project</action>
    <action>Validate implementation meets ALL story acceptance criteria; enforce quantitative thresholds explicitly</action>
    <action if="regression tests fail">STOP and fix before continuing - identify breaking changes immediately</action>
    <action if="new tests fail">STOP and fix before continuing - ensure implementation correctness</action>
  </step>

  <step n="8" goal="Validate and mark task complete ONLY when fully done">
    <critical>NEVER mark a task complete unless ALL conditions are met - NO LYING OR CHEATING</critical>
    <critical>REMEMBER YOUR COMMIT CONTRACT - You MUST commit after this task completes</critical>

    <!-- VALIDATION GATES -->
    <action>Verify ALL tests for this task/subtask ACTUALLY EXIST and PASS 100%</action>
    <action>Confirm implementation matches EXACTLY what the task/subtask specifies - no extra features</action>
    <action>Validate that ALL acceptance criteria related to this task are satisfied</action>
    <action>Run full test suite to ensure NO regressions introduced</action>

    <!-- REVIEW FOLLOW-UP HANDLING -->
    <check if="task is review follow-up (has [AI-Review] prefix)">
      <action>Extract review item details (severity, description, related AC/file)</action>
      <action>Add to resolution tracking list: {{resolved_review_items}}</action>

      <!-- Mark task in Review Follow-ups section -->
      <action>Mark task checkbox [x] in "Tasks/Subtasks ‚Üí Review Follow-ups (AI)" section</action>

      <!-- CRITICAL: Also mark corresponding action item in review section -->
      <action>Find matching action item in "Senior Developer Review (AI) ‚Üí Action Items" section by matching description</action>
      <action>Mark that action item checkbox [x] as resolved</action>

      <action>Add to Dev Agent Record ‚Üí Completion Notes: "‚úÖ Resolved review finding [{{severity}}]: {{description}}"</action>
    </check>

    <!-- ONLY MARK COMPLETE IF ALL VALIDATION PASS -->
    <check if="ALL validation gates pass AND tests ACTUALLY exist and pass">
      <action>ONLY THEN mark the task (and subtasks) checkbox with [x]</action>
      <action>Update File List section with ALL new, modified, or deleted files (paths relative to repo root)</action>
      <action>Add completion notes to Dev Agent Record summarizing what was ACTUALLY implemented and tested</action>

      <check if="review_continuation == true and {{resolved_review_items}} is not empty">
        <action>Count total resolved review items in this session</action>
        <action>Add Change Log entry: "Addressed code review findings - {{resolved_count}} items resolved (Date: {{date}})"</action>
      </check>

      <action>Save the story file</action>
      <action>Set {{task_validated}} = true</action>
    </check>

    <check if="ANY validation fails">
      <action>DO NOT mark task complete - fix issues first</action>
      <action>Set {{task_validated}} = false</action>
      <action>HALT if unable to fix validation failures</action>
    </check>

    <!-- ============================================================== -->
    <!-- MANDATORY COMMIT SEQUENCE - HONORING THE COMMIT CONTRACT       -->
    <!-- ============================================================== -->
    <critical>üîí COMMIT CONTRACT ENFORCEMENT - This is your binding commitment from Step 2</critical>
    <critical>COMMIT IS MANDATORY - Agent MUST NOT proceed to next task without completing this entire sequence</critical>

    <check if="{{task_validated}} == true">
      <!-- Determine commit type based on task nature -->
      <action>Determine commit type from task description:
        - If task mentions "fix", "bug", "resolve", "address" ‚Üí type = "fix"
        - If task mentions "test", "spec", "coverage" ‚Üí type = "test"
        - If task mentions "refactor", "restructure", "reorganize" ‚Üí type = "refactor"
        - If task mentions "docs", "documentation", "readme" ‚Üí type = "docs"
        - If task is [AI-Review] follow-up ‚Üí type = "fix"
        - Otherwise ‚Üí type = "feat"
      </action>
      <action>Store commit type as {{commit_type}}</action>

      <!-- Generate conventional commit message -->
      <action>Generate commit message in conventional format:
        Line 1: {{commit_type}}(story-{{story_key}}): {{task_summary_lowercase}}
        Line 2: (blank)
        Line 3+: Brief description of what was implemented (1-2 sentences max)
      </action>

      <action>Stage all changes: git add -A</action>
      <action>Commit with conventional message format using HEREDOC:
        git commit -m "$(cat &lt;&lt;'EOF'
        {{commit_type}}(story-{{story_key}}): {{task_summary_lowercase}}

        {{brief_implementation_description}}
        EOF
        )"
      </action>
      <action>Run: git rev-parse HEAD</action>
      <action>Store result as {{last_commit_sha}}</action>
      <action>Increment {{tasks_committed}} counter</action>

      <!-- MANDATORY: Verbalize contract honored -->
      <critical>MUST explicitly state the contract honored message - this is NOT optional</critical>
      <output>‚úÖ **COMMIT CONTRACT HONORED - Task {{current_task_number}} committed**

        ```
        {{commit_type}}(story-{{story_key}}): {{task_summary_lowercase}}
        ```
        SHA: {{last_commit_sha}}

        Tasks committed this session: {{tasks_committed}}
        Contract Status: HONORED ‚úì
      </output>

      <!-- CONTINUOUS EXECUTION CONTRACT ENFORCEMENT -->
      <critical>‚ö° CONTINUOUS EXECUTION CONTRACT - Proceeding immediately to next task without pause</critical>
    </check>

    <!-- HALT GATE - Prevents progression without verified commit -->
    <critical>HALT GATE: Cannot proceed to next task without verified commit</critical>
    <check if="{{task_validated}} == true AND {{last_commit_sha}} is NOT set">
      <action>HALT: "üö® COMMIT CONTRACT VIOLATION - Task marked complete but commit verification failed. Run git add -A &amp;&amp; git commit before continuing."</action>
    </check>

    <!-- TASK CONTINUATION - Only allowed after commit verification -->
    <action>Determine if more incomplete tasks remain</action>
    <check if="more tasks remain">
      <check if="{{last_commit_sha}} is NOT set AND {{task_validated}} == true">
        <action>HALT: "üö® COMMIT CONTRACT VIOLATION - Cannot proceed without verified commit"</action>
      </check>
      <action>Clear {{last_commit_sha}} for next task cycle</action>
      <action>Clear {{task_validated}} for next task cycle</action>
      <output>‚û°Ô∏è **Continuing** (Execution Contract Honored) - Moving to next task</output>
      <goto step="5">Next task</goto>
    </check>
    <check if="no tasks remain">
      <goto step="9">Completion</goto>
    </check>
  </step>

  <step n="9" goal="Story completion and mark for review" tag="sprint-status">
    <!-- COMMIT CONTRACT FINAL VALIDATION -->
    <critical>Verify commit contract was honored throughout the session</critical>
    <action>Compare {{tasks_committed}} against {{current_task_number}}</action>
    <check if="{{tasks_committed}} != {{current_task_number}}">
      <output>üö® **COMMIT CONTRACT VIOLATION DETECTED**
        Tasks completed: {{current_task_number}}
        Tasks committed: {{tasks_committed}}
        Missing commits: {{current_task_number - tasks_committed}}

        The commit contract was NOT honored. Some tasks were batched together.
      </output>
      <action>HALT: "Commit contract violation - tasks were not committed individually"</action>
    </check>
    <check if="{{tasks_committed}} == {{current_task_number}}">
      <output>‚úÖ **COMMIT CONTRACT FULLY HONORED**
        All {{tasks_committed}} tasks were committed individually as required.
      </output>
    </check>

    <action>Verify ALL tasks and subtasks are marked [x] (re-scan the story document now)</action>
    <action>Run the full regression suite (do not skip)</action>
    <action>Confirm File List includes every changed file</action>
    <action>Load and execute definition-of-done checklist from {validation}</action>
    <action>Execute enhanced definition-of-done validation per checklist criteria</action>
    <action>Update the story Status to: "Ready for Review"</action>

    <!-- Enhanced Definition of Done Validation -->
    <action>Validate definition-of-done checklist with essential requirements:
      - All tasks/subtasks marked complete with [x]
      - Implementation satisfies every Acceptance Criterion
      - Unit tests for core functionality added/updated
      - Integration tests for component interactions added when required
      - End-to-end tests for critical flows added when story demands them
      - All tests pass (no regressions, new tests successful)
      - Code quality checks pass (linting, static analysis if configured)
      - File List includes every new/modified/deleted file (relative paths)
      - Dev Agent Record contains implementation notes
      - Change Log includes summary of changes
      - Only permitted story sections were modified
    </action>

    <!-- Mark story ready for review - sprint status conditional -->
    <check if="{sprint_status} file exists AND {{current_sprint_status}} != 'no-sprint-tracking'">
      <action>Load the FULL file: {sprint_status}</action>
      <action>Find development_status key matching {{story_key}}</action>
      <action>Verify current status is "in-progress" (expected previous state)</action>
      <action>Update development_status[{{story_key}}] = "review"</action>
      <action>Save file, preserving ALL comments and structure including STATUS DEFINITIONS</action>
      <output>‚úÖ Story marked Ready for Review in sprint status</output>
    </check>

    <check if="{sprint_status} file does NOT exist OR {{current_sprint_status}} == 'no-sprint-tracking'">
      <output>‚ÑπÔ∏è Story marked Ready for Review in story file (no sprint tracking configured)</output>
    </check>

    <check if="story key not found in sprint status">
      <output>‚ö†Ô∏è Story file updated, but sprint-status update failed: {{story_key}} not found

        Story is marked Ready for Review in file, but sprint-status.yaml may be out of sync.
      </output>
    </check>

    <!-- Final validation gates -->
    <action if="any task is incomplete">HALT - Complete remaining tasks before marking ready for review</action>
    <action if="regression failures exist">HALT - Fix regression issues before completing</action>
    <action if="File List is incomplete">HALT - Update File List with all changed files</action>
    <action if="definition-of-done validation fails">HALT - Address DoD failures before completing</action>
  </step>

  <step n="10" goal="Completion communication and user support">
    <action>Execute the enhanced definition-of-done checklist using the validation framework</action>
    <action>Prepare a concise summary in Dev Agent Record ‚Üí Completion Notes</action>

    <action>Communicate to {user_name} that story implementation is complete and ready for review</action>
    <action>Summarize key accomplishments: story ID, story key, title, key changes made, tests added, files modified</action>
    <action>Provide the story file path and current status (now "Ready for Review")</action>

    <action>Based on {user_skill_level}, ask if user needs any explanations about:
      - What was implemented and how it works
      - Why certain technical decisions were made
      - How to test or verify the changes
      - Any patterns, libraries, or approaches used
      - Anything else they'd like clarified
    </action>

    <check if="user asks for explanations">
      <action>Provide clear, contextual explanations tailored to {user_skill_level}</action>
      <action>Use examples and references to specific code when helpful</action>
    </check>

    <action>Once explanations are complete (or user indicates no questions), suggest logical next steps</action>
    <action>Recommended next steps (flexible based on project setup):
      - Review the implemented story and test the changes
      - Verify all acceptance criteria are met
      - Ensure deployment readiness if applicable
      - Run `code-review` workflow for peer review
    </action>

    <output>üí° **Tip:** For best results, run `code-review` using a **different** LLM than the one that implemented this story.</output>
    <check if="{sprint_status} file exists">
      <action>Suggest checking {sprint_status} to see project progress</action>
    </check>
    <action>Remain flexible - allow user to choose their own path or ask for other assistance</action>
  </step>

</workflow>